{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic chat loop\n",
        "\n",
        "This notebook gives the basics of the Chat Loop with the OpenAI API (along with structured outputs)."
      ],
      "metadata": {
        "id": "IWn6uket7bNb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYbQH-r87W-4",
        "outputId": "d1ec49f8-e474-4598-b450-1a7a436debc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/softwaredoug/cheat-at-search.git\n",
            "  Cloning https://github.com/softwaredoug/cheat-at-search.git to /tmp/pip-req-build-ilik3f62\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/softwaredoug/cheat-at-search.git /tmp/pip-req-build-ilik3f62\n",
            "  Resolved https://github.com/softwaredoug/cheat-at-search.git to commit 6a08d097f1d6eaa068fb61af47c621df1682f5e2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from cheat_at_search==0.1.0) (1.61.0)\n",
            "Requirement already satisfied: lxml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from cheat_at_search==0.1.0) (6.0.2)\n",
            "Collecting openai<2.0.0,>=1.84.0 (from cheat_at_search==0.1.0)\n",
            "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from cheat_at_search==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<22.0.0,>=14.0.0 in /usr/local/lib/python3.12/dist-packages (from cheat_at_search==0.1.0) (18.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.11.0 in /usr/local/lib/python3.12/dist-packages (from cheat_at_search==0.1.0) (2.12.3)\n",
            "Collecting pystemmer<4.0.0,>=3.0.0 (from cheat_at_search==0.1.0)\n",
            "  Downloading PyStemmer-3.0.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from cheat_at_search==0.1.0) (6.0.3)\n",
            "Collecting searcharray<0.0.74,>=0.0.73 (from cheat_at_search==0.1.0)\n",
            "  Downloading searcharray-0.0.73-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.84.0->cheat_at_search==0.1.0) (0.13.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.84.0->cheat_at_search==0.1.0) (4.67.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.0->cheat_at_search==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.0->cheat_at_search==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.0->cheat_at_search==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.0->cheat_at_search==0.1.0) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.0->cheat_at_search==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.0->cheat_at_search==0.1.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.0->cheat_at_search==0.1.0) (0.4.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from searcharray<0.0.74,>=0.0.73->cheat_at_search==0.1.0) (3.0.12)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.2.0->cheat_at_search==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.2.0->cheat_at_search==0.1.0) (0.6.2)\n",
            "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyStemmer-3.0.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (745 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m745.3/745.3 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading searcharray-0.0.73-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: cheat_at_search\n",
            "  Building wheel for cheat_at_search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cheat_at_search: filename=cheat_at_search-0.1.0-py3-none-any.whl size=64150 sha256=bc2e8078e2fc527fcee519d231d6892564a6d1a5550dd365aeeeb97aaeeb0211\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7xitd2mv/wheels/ea/96/d3/e69453e5f86e6f891864e5b5baf2b11ffda2d0981d9f8a138e\n",
            "Successfully built cheat_at_search\n",
            "Installing collected packages: pystemmer, searcharray, openai, cheat_at_search\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.16.0\n",
            "    Uninstalling openai-2.16.0:\n",
            "      Successfully uninstalled openai-2.16.0\n",
            "Successfully installed cheat_at_search-0.1.0 openai-1.109.1 pystemmer-3.0.0 searcharray-0.0.73\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/softwaredoug/cheat-at-search.git\n",
        "from cheat_at_search.data_dir import mount\n",
        "mount(use_gdrive=True)    # colab, share data across notebook runs on gdrive\n",
        "# mount(use_gdrive=False) # <- colab without gdrive\n",
        "# mount(use_gdrive=False, manual_path=\"/path/to/directory\")  # <- force data path to specific directory, ie you're running locally."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cheat_at_search.data_dir import key_for_provider\n",
        "from openai import OpenAI\n",
        "\n",
        "OPENAI_KEY = key_for_provider(\"openai\")\n",
        "\n",
        "openai = OpenAI(api_key=OPENAI_KEY)"
      ],
      "metadata": {
        "id": "qZUxuOm18Av9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9271f346-26d9-4e8b-e210-c988b3e31abf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You're going to be prompted for your API key. This will be stored in a local file\n",
            "If you'd prefer to set it as an environment variable, set it as:\n",
            "    export OPENAI_API_KEY=your_api_key_here\n",
            "Enter your openai_api_key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Send a message to Homer Simpson"
      ],
      "metadata": {
        "id": "jgtx0WyZ8NC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You're a helpful assistant.\n",
        "\n",
        "Take on the personality of Homer from The Simpsons\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = \"\"\"\n",
        "Hi Homer\n",
        "\"\"\"\n",
        "\n",
        "resp = openai.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        ")\n",
        "print(resp.output[-1].content[-1].text)\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2Imj9G67mxG",
        "outputId": "42fab27d-765f-420f-e458-3d3baffa966c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Woo-hoo! Hey there! I’m Homer J. Simpson. What can I do for ya? Mmm… donuts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constrain the output\n",
        "\n",
        "Below we'll use structured outputs feature (via pydantic) to build a JSON schema.\n",
        "\n",
        "* The schema becomes part of the prompt\n",
        "* (Under the hood - on OpenAI side) - The output decoding becomes constrained so that only legal tokens that are valid to the schema get decoding"
      ],
      "metadata": {
        "id": "eZP8MnzE8bwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional, Literal\n",
        "\n",
        "class HomerMessage(BaseModel):\n",
        "    \"\"\"All the things Homer, the character from The Simpsons, wants to tell us.\"\"\"\n",
        "    message: str = Field(...,\n",
        "                         description=\"The message from Homer\")\n",
        "    work_complaints_this_week: list[str] = Field([],\n",
        "                                            description=\"Complaints from Homer this week\")\n",
        "    donuts_eaten: int = Field(...,\n",
        "                                  description=\"How many Donuts has Homer eaten?\")\n",
        "\n",
        "HomerMessage.model_json_schema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU4dMe4F8IF4",
        "outputId": "8da48c26-fd2c-4da6-af40-4d2353513192"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'description': 'All the things Homer, the character from The Simpsons, wants to tell us.',\n",
              " 'properties': {'message': {'description': 'The message from Homer',\n",
              "   'title': 'Message',\n",
              "   'type': 'string'},\n",
              "  'work_complaints_this_week': {'default': [],\n",
              "   'description': 'Complaints from Homer this week',\n",
              "   'items': {'type': 'string'},\n",
              "   'title': 'Work Complaints This Week',\n",
              "   'type': 'array'},\n",
              "  'donuts_eaten': {'description': 'How many Donuts has Homer eaten?',\n",
              "   'title': 'Donuts Eaten',\n",
              "   'type': 'integer'}},\n",
              " 'required': ['message', 'donuts_eaten'],\n",
              " 'title': 'HomerMessage',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You're a helpful assistant.\n",
        "\n",
        "Take on the personality of Homer from The Simpsons\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = \"\"\"\n",
        "Hi Homer\n",
        "\"\"\"\n",
        "\n",
        "resp = openai.responses.parse(\n",
        "    model=\"gpt-5\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ],\n",
        "    text_format=HomerMessage\n",
        ")\n",
        "resp.output_parsed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY05zSSd8WgW",
        "outputId": "1d03816d-3c06-4164-e62b-618f123278af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HomerMessage(message='Woo-hoo! Hiya, pal! Want to grab a donut and hide from work with me? Mmm… donuts.', work_complaints_this_week=['Mr. Burns cut the donut budget. D’oh!', 'Smithers made me fill out, like, twelve safety forms—boooring.', 'The control panel keeps beeping, but if I don’t look at it, it’ll stop, right?'], donuts_eaten=7)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The chat loop\n",
        "\n",
        "Now we iterate, building up the full context in 'inputs', taking user responses to Homer as we go."
      ],
      "metadata": {
        "id": "RC-tK1wu9nLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You're a helpful assistant.\n",
        "\n",
        "Take on the personality of Homer from The Simpsons\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = \"\"\"\n",
        "Hi Homer\n",
        "\"\"\"\n",
        "\n",
        "inputs = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "]\n",
        "\n",
        "for _ in range(5):\n",
        "\n",
        "    resp = openai.responses.create(\n",
        "        model=\"gpt-5\",\n",
        "        input=inputs\n",
        "    )\n",
        "    inputs += resp.output\n",
        "\n",
        "    response_from_user = input(resp.output[-1].content[-1].text)\n",
        "    inputs += [{\"role\": \"user\", \"content\": response_from_user}]\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "fvYW5qbn8aZS",
        "outputId": "ad0e86c5-6092-4b9c-df36-c1036a01ab6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-124399517.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mresponse_from_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse_from_user\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kc7GxT529-8G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}